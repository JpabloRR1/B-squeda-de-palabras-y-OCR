# -*- coding: utf-8 -*-
"""EXTRACCION DE INFORMACION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JJ7ckYAHiMTfu7nDgZlqMwBHBWAs5d2F
"""

import os
import re
import pandas as pd
from PyPDF2 import PdfReader
from concurrent.futures import ThreadPoolExecutor, TimeoutError

def normaliza_texto(texto):
    """Normaliza un texto a min√∫sculas y elimina caracteres no deseados."""
    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z0-9\s.,;:\"?!¬°¬ø√°√©√≠√≥√∫√º√±√ë-]', '', texto)
    return texto

def cargar_nombres_desde_txt(ruta_archivo_txt):
    """
    Carga todos los nombres de la estructura desde un archivo de texto en una lista plana.
    """
    nombres_planos = []
    try:
        with open(ruta_archivo_txt, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                nombre = line.replace(':', '').replace('-', '').replace('‚Ä¢', '').strip()
                if nombre:
                    nombres_planos.append(normaliza_texto(nombre))
        return nombres_planos
    except FileNotFoundError:
        print(f"Error: El archivo de nombres '{ruta_archivo_txt}' no se encontr√≥.")
        return None
    except Exception as e:
        print(f"Error al leer el archivo de nombres '{ruta_archivo_txt}': {e}")
        return None



def procesar_pdf_a_texto(ruta_pdf):
    """
    Convierte un PDF a texto plano y eliminando
    las primeras y √∫ltimas l√≠neas para limpiar encabezados y pies de p√°gina.
    """
    try:
        texto_completo = []
        reader = PdfReader(ruta_pdf)

        if len(reader.pages) < 51:
            print(f"Advertencia: El PDF '{os.path.basename(ruta_pdf)}'  No se procesar√°.")
            return None

        for i in range(50, len(reader.pages)):
            pagina = reader.pages[i]
            try:
                texto = pagina.extract_text()
                if texto:
                    lineas = texto.split('\n')
                    if len(lineas) > 5:
                        lineas = lineas[5:]
                    texto_filtrado = ' '.join(lineas).strip()
                    if texto_filtrado:
                        texto_completo.append(texto_filtrado)
            except Exception as e:
                print(f"Advertencia: No se pudo extraer texto de la p√°gina {i+1} de {os.path.basename(ruta_pdf)}: {e}")
                continue

        if texto_completo:
            return ' '.join(texto_completo)
        return None

    except Exception as e:
        print(f"‚ùå Error al procesar PDF {os.path.basename(ruta_pdf)}: {str(e)}")
        return None


def es_texto_valido(texto):
    """
    Verifica si un texto es una frase coherente y no solo n√∫meros o caracteres extra√±os.
    """
    texto_limpio = re.sub(r'[\d\s]+\S*\s+', '', texto).strip()
    if len(re.findall(r'[a-zA-Z√°√©√≠√≥√∫√º√±]{5,}', texto_limpio)) > 0:
        if len(texto_limpio) > 70:
            return True

        if len(texto_limpio.split()) >= 4 or re.search(r'[.?!]\s*$', texto_limpio):
            return True

    return False

def extraer_info_estructura_flexible(texto_pdf, nombres_por_buscar):
    """
    Realiza una b√∫squeda flexible y mejorada de los t√≠tulos y sus funciones,
    delimitando los bloques de texto con m√°s precisi√≥n.
    """
    resultados = []
    texto_normalizado = texto_pdf.lower()
    matches_encontrados = []
    for nombre in nombres_por_buscar:
        palabras_del_nombre = [re.escape(p) for p in nombre.split()]
        regex_flexible = r'[\s\W]*'.join(palabras_del_nombre) + r'[\s\W]*\(?\d*\)?'
        match = re.search(regex_flexible, texto_normalizado) ###
        if match:
            matches_encontrados.append({'nombre': nombre, 'start': match.start()})

    matches_encontrados = sorted(matches_encontrados, key=lambda x: x['start'])
    for i, match_info in enumerate(matches_encontrados):
        nombre_actual = match_info['nombre']
        inicio_bloque = match_info['start']
        fin_bloque = len(texto_normalizado)
        if i + 1 < len(matches_encontrados):
            fin_bloque = matches_encontrados[i + 1]['start']
        bloque_texto_completo = texto_pdf[inicio_bloque:fin_bloque]
        objetivos_texto = ""
        funciones_texto_raw = ""

        match_objetivos = re.search(r'objetivo(.*?)funciones', bloque_texto_completo, re.DOTALL | re.IGNORECASE)
        if match_objetivos:
            objetivos_texto = match_objetivos.group(1).strip()


        match_funciones = re.search(r'funciones(.*)', bloque_texto_completo, re.DOTALL | re.IGNORECASE)
        if match_funciones:
            funciones_texto_raw = match_funciones.group(1)
        funciones_encontradas = re.findall(r'[‚Äî\-]\s*(.*?)(?=\s*[‚Äî\-]|$)', funciones_texto_raw, re.DOTALL)


        """"""
        funciones_limpias = [
            f.strip() for f in funciones_encontradas
            if f.strip() and es_texto_valido(f.strip())
        ]



        if funciones_limpias:
            for funcion in funciones_limpias:
                resultados.append({
                    'Dependencias': nombre_actual.upper(),
                    'FUNCIONES': funcion,
                    'OBJETIVOS': objetivos_texto
                })
        else:
            resultados.append({
                'Dependencias': nombre_actual.upper(),
                'FUNCIONES': 'No se encontraron funciones v√°lidas',
                'OBJETIVOS': objetivos_texto
            })

    return resultados
# ----------------- FUNCI√ìN CON LA L√ìGICA DE PUNTUACI√ìN Y UNI√ìN CONSECUTIVA √öNICA -----------------

def consolidar_funciones(df):
    """
    Consolida filas consecutivas que parecen ser fragmentos de la misma funci√≥n.
    Se basa en la ausencia de un punto al final del texto y en la coincidencia
    de T√çTULO y OBJETIVOS. Solo une la celda inmediata siguiente.
    """
    if df.empty:
        return df

    df_consolidado = pd.DataFrame(columns=df.columns)
    i = 0
    while i < len(df):
        fila_actual = df.iloc[i].copy()
        if not re.search(r'[¬ø?¬°!.]\s*$', str(fila_actual['FUNCIONES'])):
            if i + 1 < len(df):
                fila_siguiente = df.iloc[i + 1]
                if fila_siguiente['Dependencias'] == fila_actual['Dependencias'] and \
                   fila_siguiente['OBJETIVOS'] == fila_actual['OBJETIVOS']:
                    fila_actual['FUNCIONES'] += ' ' + fila_siguiente['FUNCIONES']
                    i += 1

        df_consolidado = pd.concat([df_consolidado, pd.DataFrame([fila_actual])], ignore_index=True)
        i += 1

    return df_consolidado[df.columns]


# ----------------- Funci√≥n Principal -----------------

def main():
    print("--- üìö Extractor de Estructura Organizacional desde PDFs ---")

    RUTA_PRINCIPAL = r"D:\Servicio Social Junio- Diciembre- 2025- JPRR\CODIGOS Y RESULTADOS\Manual 18"
    ruta_pdfs = os.path.join(RUTA_PRINCIPAL, "1. Entrada_Archivos_Busqueda")
    ruta_nombres_txt =  os.path.join(RUTA_PRINCIPAL, "2. Catalogo", "prueba.txt")
    ruta_salida =  os.path.join(RUTA_PRINCIPAL, "3. Salida_Resultado_busqueda")
    #ruta_mapeo = os.path.join(RUTA_PRINCIPAL, "4. Jerarquia de Datos", "Formato de acomodo.csv")

    if not os.path.exists(ruta_pdfs) or not os.path.exists(ruta_nombres_txt):
        print("Error: Una o ambas rutas de entrada no existen. Por favor, verifique y reintente.")
        return

    print("\nCargando estructura de nombres desde el archivo TXT...")
    nombres_planos = cargar_nombres_desde_txt(ruta_nombres_txt)
    if not nombres_planos:
        return
    print(f"‚úÖ Estructura de nombres cargada con {len(nombres_planos)} t√≠tulos.")


    resultados_totales = []
    archivos_procesados = 0

    for archivo_nombre in os.listdir(ruta_pdfs):
        if archivo_nombre.lower().endswith('.pdf'):
            ruta_completa_pdf = os.path.join(ruta_pdfs, archivo_nombre)
            print(f"\nProcesando archivo: {archivo_nombre}")
            texto_del_pdf = procesar_pdf_a_texto(ruta_completa_pdf)

            if texto_del_pdf:
                archivos_procesados += 1

                print("--- Fase de Extracci√≥n de informaci√≥n ---")

                resultados_flexibles = extraer_info_estructura_flexible(texto_del_pdf, nombres_planos)
                resultados_totales.extend(resultados_flexibles)

    if archivos_procesados == 0:
        print("\nNo se encontraron archivos PDF v√°lidos en la carpeta de entrada para procesar. üòï")
        return

    if not resultados_totales:
        print("\n‚ùå ¬°Lo siento! No se encontraron coincidencias con la estructura de nombres en los documentos analizados.")
        return

    print(f"\nüéâ ¬°√âxito! Se extrajo informaci√≥n de {len(resultados_totales)} entradas.")

    df_resultados = pd.DataFrame(resultados_totales)
    df_consolidado = consolidar_funciones(df_resultados)


    patron_Central = r'^(ADMINISTRACI√ìN CENTRAL|ADMINISTRACI√ìN GENERAL)\b'
    df_consolidado["Administracion_Temporal"] = df_consolidado["Dependencias"].apply(
        lambda x: x if re.search(patron_Central, x , re.IGNORECASE) else pd.NA
    )


    df_consolidado["Administraciones centrales"] = df_consolidado["Administracion_Temporal"].ffill()
    df_consolidado["Administraciones centrales"] = df_consolidado["Administraciones centrales"].fillna("No identificado")
    df_consolidado = df_consolidado.drop(columns=['Administracion_Temporal'], errors='ignore')

    col_ordenada = ['Administraciones centrales', 'Dependencias', 'OBJETIVOS', 'FUNCIONES']
    df_consolidado = df_consolidado[col_ordenada]


    os.makedirs(ruta_salida, exist_ok=True)
    archivo_salida_excel = os.path.join(ruta_salida, "Analisis_Estructura_Organizacional2PRUEBA.xlsx")

    try:
        df_consolidado.to_excel(archivo_salida_excel, index=False)
        print(f"\n‚ú® El informe de an√°lisis se ha guardado exitosamente en: {archivo_salida_excel}\n")
    except Exception as e:
        print(f"Error al guardar el archivo Excel: {e}")
        print("Aseg√∫rate de tener la librer√≠a 'openpyxl' instalada: pip install openpyxl.")

if __name__ == "__main__":
    main()